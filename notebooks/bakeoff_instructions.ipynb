{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Bakeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Paul Hollywood gif](https://media.giphy.com/media/OjrcZp4fXMHBryKoXZ/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferential vs. Predictive\n",
    "You should think of this primarily as a project in **inferential** statistics. That means:\n",
    "- focusing on trying to satisfy the assumptions of linear regression;\n",
    "- using all your records to build models;\n",
    "- aiming for understanding how features influence sales prices.\n",
    "\n",
    "But we also invite you to a level-up: a friendly competition among the teams. And here the goal is **predictive**. That means:\n",
    "- maximizing $R^2$;\n",
    "- utilizing train-test splits;\n",
    "- utilizing validation sets (or cross-validation).\n",
    "Weâ€™ll have SOME UNLABELED TEST DATA FOR YOU TO PLUG INTO YOUR MODELS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like a Kaggle competition, you are provided with the following training data representing 3/4 of the data set.  \n",
    "It is split into **predictive features** (X_train) and **target variable** (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train = pd.read_csv('bakeoff_data/Xtrain.csv')\n",
    "y_train = pd.read_csv('bakeoff_data/ytrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16197, 19)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16197, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/4/2015</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1880</td>\n",
       "      <td>4499</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98029</td>\n",
       "      <td>47.5664</td>\n",
       "      <td>-121.999</td>\n",
       "      <td>2130</td>\n",
       "      <td>5114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/7/2014</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2020</td>\n",
       "      <td>6564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1310</td>\n",
       "      <td>710.0</td>\n",
       "      <td>1994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98042</td>\n",
       "      <td>47.3545</td>\n",
       "      <td>-122.158</td>\n",
       "      <td>1710</td>\n",
       "      <td>5151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/16/2015</td>\n",
       "      <td>5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4720</td>\n",
       "      <td>493534</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3960</td>\n",
       "      <td>760.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.4536</td>\n",
       "      <td>-122.009</td>\n",
       "      <td>2160</td>\n",
       "      <td>219542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/30/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1430</td>\n",
       "      <td>3880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98117</td>\n",
       "      <td>47.6844</td>\n",
       "      <td>-122.392</td>\n",
       "      <td>1430</td>\n",
       "      <td>3880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/14/2014</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2270</td>\n",
       "      <td>32112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1740</td>\n",
       "      <td>530.0</td>\n",
       "      <td>1980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98042</td>\n",
       "      <td>47.3451</td>\n",
       "      <td>-122.094</td>\n",
       "      <td>2310</td>\n",
       "      <td>41606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0    3/4/2015         3       2.50         1880      4499     2.0         0.0   \n",
       "1   10/7/2014         3       2.50         2020      6564     1.0         0.0   \n",
       "2   1/16/2015         5       4.00         4720    493534     2.0         0.0   \n",
       "3   3/30/2015         2       2.00         1430      3880     1.0         0.0   \n",
       "4  10/14/2014         3       2.25         2270     32112     1.0         0.0   \n",
       "\n",
       "   view  condition  grade  sqft_above sqft_basement  yr_built  yr_renovated  \\\n",
       "0   0.0          3      8        1880           0.0      1993           0.0   \n",
       "1   0.0          3      7        1310         710.0      1994           0.0   \n",
       "2   0.0          5      9        3960         760.0      1975           0.0   \n",
       "3   0.0          4      7        1430           0.0      1949           0.0   \n",
       "4   0.0          4      8        1740         530.0      1980           0.0   \n",
       "\n",
       "   zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "0    98029  47.5664 -121.999           2130        5114  \n",
       "1    98042  47.3545 -122.158           1710        5151  \n",
       "2    98027  47.4536 -122.009           2160      219542  \n",
       "3    98117  47.6844 -122.392           1430        3880  \n",
       "4    98042  47.3451 -122.094           2310       41606  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, you have been provided with 19 independent features.  You may use as many of them as you like in your model.  The goal is to get the highest R^2 on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how will you know that your model resulted in a high R^2 in the test data? You won't! At least, you won't know until the submission window has closed.  \n",
    "\n",
    "You will notice that while you have a file named `Xtest.csv`, you do not have a file named `ytest.csv`. Your instructor has that in their posession, and will keep it secret from the bakeoff contestants.  \n",
    "\n",
    "Once you have decided on your best model, you will then make predictions.  These predictions will be compared to the labels held in the hidden `ytest.csv`, resulting in a final R^2 score. In order for your submission to be valid, you have to have a prediction for every row of `Xtest.csv`.\n",
    "\n",
    "Below, the `Xtest.csv` has been imported into this notebook for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/20/2015</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>850</td>\n",
       "      <td>8573</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5030</td>\n",
       "      <td>-122.356</td>\n",
       "      <td>850</td>\n",
       "      <td>8382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/8/2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1510</td>\n",
       "      <td>6083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>860</td>\n",
       "      <td>650.0</td>\n",
       "      <td>1940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98115</td>\n",
       "      <td>47.6966</td>\n",
       "      <td>-122.324</td>\n",
       "      <td>1510</td>\n",
       "      <td>5712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/25/2015</td>\n",
       "      <td>4</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1790</td>\n",
       "      <td>42000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1170</td>\n",
       "      <td>620.0</td>\n",
       "      <td>1983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98045</td>\n",
       "      <td>47.4819</td>\n",
       "      <td>-121.744</td>\n",
       "      <td>2060</td>\n",
       "      <td>50094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/17/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1140</td>\n",
       "      <td>2500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>630</td>\n",
       "      <td>510.0</td>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98106</td>\n",
       "      <td>47.5707</td>\n",
       "      <td>-122.359</td>\n",
       "      <td>1500</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/23/2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1500</td>\n",
       "      <td>3920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98107</td>\n",
       "      <td>47.6718</td>\n",
       "      <td>-122.359</td>\n",
       "      <td>1640</td>\n",
       "      <td>4017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0  2/20/2015         3       0.75          850      8573     1.0         0.0   \n",
       "1  10/8/2014         3       1.00         1510      6083     1.0         0.0   \n",
       "2  3/25/2015         4       2.25         1790     42000     1.0         0.0   \n",
       "3  2/17/2015         2       1.50         1140      2500     1.0         0.0   \n",
       "4  5/23/2014         3       1.00         1500      3920     1.0         0.0   \n",
       "\n",
       "   view  condition  grade  sqft_above sqft_basement  yr_built  yr_renovated  \\\n",
       "0   0.0          3      6         600         250.0      1945           0.0   \n",
       "1   0.0          4      6         860         650.0      1940           0.0   \n",
       "2   0.0          3      7        1170         620.0      1983           0.0   \n",
       "3   1.0          3      7         630         510.0      1988           NaN   \n",
       "4   0.0          3      7        1000         500.0      1947           0.0   \n",
       "\n",
       "   zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "0    98146  47.5030 -122.356            850        8382  \n",
       "1    98115  47.6966 -122.324           1510        5712  \n",
       "2    98045  47.4819 -121.744           2060       50094  \n",
       "3    98106  47.5707 -122.359           1500        5000  \n",
       "4    98107  47.6718 -122.359           1640        4017  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv('bakeoff_data/Xtest.csv')\n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 19)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the cell above indicates that there are **5400** records in `X_test`.  You should therefore submit 5400 predicted saleprices.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Your Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how does one build a model that one has confidence will perform well on the test data? You could just fit the model on the training data, and consider the R^2.  But remember, no matter what, your training R^2  will always go up when you add more features. With that in mind, you could just implement a 6th degree polynomial transformation, and your training R^2 will be very high.  What will that mean in terms of the bias-variance tradeoff?  Your model will be highly complex and surely overfit. Therefore, you would expect it to perform poorly on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of how your model will perform on unseen data, you will have to choose some method of creating a validation set within your training data.  \n",
    "\n",
    "There are several ways to do that, and you will have to pick the method that you are most comfortable with.  \n",
    "\n",
    "The simplest way would be to simply perform another train-test-split on your training data, fit your model on the larger part of that secondary split, and then score your model on the smaller validation set. \n",
    "\n",
    "The more comprehensive way would be to use the Sklearn cross-validation class or Kfolds.  If you specify 5 folds, then you train your model on 5 different sets of training data and 5 different sets of validation data.  You would then look at the mean R^2 of the 5 validation sets.\n",
    "\n",
    "Your task will be to try out different hypotheses iteratively, and select the combination of predictors that explains the most variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have selected your best combination of features, your work is not quite done. You have to use your trained model to make predictions.  In doing so, you have to watch out for a few stumbling points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Retrain Your Model on the Entire Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are iteratively building your model with cross-validation, you are required to leave out some data (the validation data) in the training process.  You always want to train your model on as much data as possible. The validation process tells you which features to use in your final model, but you need to then retrain your model on the entire training data using those features.  You could not perform this step, but your model will perform worse. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Prepare your X_test Exactly as You Prepared your X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When selecting the best features for your model, you will most certainly alter your X_train data frame.  For example, maybe you did not include the `date` feature. After fitting your final model to a version of X_train without date, you then try to make a prediction on X_test.  Sklearn will complain that the dimensions of X_test do not match the demensions required on the fit model.  So, before making your predictions, you will have to drop the `date` column from X_test.  Any transformation you do to X_train will have to be performed on X_test. \n",
    "\n",
    "You will also have to deal with the missing values in the X_test.  There are 3 columns which include NA's.  You will not be able to drop rows containing missing values, since doing so will result in diminishing the number of predictions in your final set. If those columns are important to your model, you will have to fill the NA's in the test set just as you did in your training set. Of course, you could opt to not include those columns in your final model.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking your Prediction Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have selected the features for your best model, and trained your model on the entire data set.  You have transformed the X_test in the same way that you transformed your X_train.  You have made a set of predictions. \n",
    "\n",
    "In the cell below, you will find a fake y_test; it has been filled with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_test_fake = np.full((5400,1), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test that your predictions are of the correct shape, feed your 5400 predicted values into the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# fake predictions using the mean of y_train.\n",
    "your_y_hat_predictions = np.full((5400,1), np.mean(y_train))\n",
    "\n",
    "r2_score(your_y_hat_predictions, y_test_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only pay attention to errors thrown by the cell above, not the R^2.   If the cell does not throw any errors, your predictions are ready for submission.\n",
    "\n",
    "Convert the array of predictions into a `csv` by filling in the placeholder filepath and variable name with the appropriate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('your_team_member_names.csv', your_y_hat_predictions, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be a Slack channel designated for submitting your final predictions `csv`. \n",
    "\n",
    "Only predictions received before 5 pm PST will be considered valid.  \n",
    "\n",
    "The team with the highest R^2 will be deemed the Linear Regression Bakeoff winner.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![on you marks, get set, bake](https://media.giphy.com/media/l3vRhl6k5tb3oPGLK/giphy.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
